{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "skip_connections_example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPD91urZr33uOWhvd8hJQTG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DhruvSrikanth/Model-Pipelines/blob/master/skip_connections_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkOJTlDRqY7-"
      },
      "source": [
        "# ----------------------------------------------Import required Modules----------------------------------------------- #\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16, ResNet50, DenseNet121\n",
        "from tensorflow.keras.initializers import glorot_uniform"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcTmEq361xKD"
      },
      "source": [
        "def conv_block(X, f, filters, s = 2):\n",
        "\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    X_shortcut = X\n",
        "\n",
        "    X = tf.keras.layers.Conv2D(F1, kernel_size = (1, 1), strides = (s,s), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis = 3)(X)\n",
        "    X = tf.keras.activations.relu(X)\n",
        "    print('main path (post 1st conv) shape = ', X.shape)\n",
        "\n",
        "    X = tf.keras.layers.Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis = 3)(X)\n",
        "    X = tf.keras.activations.relu(X)\n",
        "    print('main path (post 2nd conv) shape = ', X.shape)\n",
        "\n",
        "    X = tf.keras.layers.Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis = 3)(X)\n",
        "    print('main path (post 3rd conv) shape = ', X.shape)\n",
        "\n",
        "    X_shortcut = tf.keras.layers.Conv2D(filters = F3, kernel_size = (1, 1), strides = (s,s), padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = tf.keras.layers.BatchNormalization(axis = 3)(X_shortcut)\n",
        "    print('shortcut  (post 1st conv) shape = ', X_shortcut.shape)\n",
        "\n",
        "    X = tf.keras.layers.Add()([X, X_shortcut])\n",
        "    X = tf.keras.activations.relu(X)\n",
        "    \n",
        "    return X"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzzznXjPqUy-"
      },
      "source": [
        "def deconv_block(X, f, filters, s = 2):\n",
        "\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    X_shortcut = X\n",
        "\n",
        "    X = tf.keras.layers.Conv2DTranspose(F1, kernel_size = (1, 1), strides = (s,s), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis = 3)(X)\n",
        "    X = tf.keras.activations.relu(X)\n",
        "    print('main path (post 1st conv) shape = ', X.shape)\n",
        "\n",
        "    X = tf.keras.layers.Conv2DTranspose(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis = 3)(X)\n",
        "    X = tf.keras.activations.relu(X)\n",
        "    print('main path (post 2nd conv) shape = ', X.shape)\n",
        "\n",
        "    X = tf.keras.layers.Conv2DTranspose(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis = 3)(X)\n",
        "    print('main path (post 3rd conv) shape = ', X.shape)\n",
        "\n",
        "    X_shortcut = tf.keras.layers.Conv2DTranspose(filters = F3, kernel_size = (1, 1), strides = (s,s), padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = tf.keras.layers.BatchNormalization(axis = 3)(X_shortcut)\n",
        "    print('shortcut  (post 1st conv) shape = ', X_shortcut.shape)\n",
        "\n",
        "    X = tf.keras.layers.Add()([X, X_shortcut])\n",
        "    X = tf.keras.activations.relu(X)\n",
        "    \n",
        "    return X"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzQP2R9cfnVx",
        "outputId": "55c617b1-cb36-40b0-c110-1dadc9f3361b"
      },
      "source": [
        "inp = tf.keras.layers.Input(shape=(224, 224, 3))\n",
        "print('Input shape = ', inp.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input shape =  (None, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plGGMH3UfHHb",
        "outputId": "eb8ec3b6-f52c-4713-e8ad-4d2a4730615b"
      },
      "source": [
        "X = conv_block(inp, f=3, filters=[16, 16, 64], s=2)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "main path (post 1st conv) shape =  (None, 112, 112, 16)\n",
            "main path (post 2nd conv) shape =  (None, 112, 112, 16)\n",
            "main path (post 3rd conv) shape =  (None, 112, 112, 64)\n",
            "shortcut  (post 1st conv) shape =  (None, 112, 112, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luddFf4jhz90"
      },
      "source": [
        "# Observations - (CONV)\n",
        "# kernel not controlling anything in input shape\n",
        "# filters controlling the 4th dim in input shape -> filter value = 3rd dim \n",
        "# stride controlling the 2nd and 3rd dims in input shape -> stride value reduces 1st and 2nd dim by a multiplier of 2x, 3x etc."
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tl0Wf1rjqx68",
        "outputId": "b8d83e2d-0bf9-4554-fbc5-a4f8be6ac99c"
      },
      "source": [
        "out = X\n",
        "print(out.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 112, 112, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulrVUrjUlkGc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11b1f5eb-cfda-459a-a7cc-25ac3e9dd311"
      },
      "source": [
        "X = deconv_block(out, f=3, filters=[64, 16, 16], s=2)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "main path (post 1st conv) shape =  (None, 224, 224, 64)\n",
            "main path (post 2nd conv) shape =  (None, 224, 224, 16)\n",
            "main path (post 3rd conv) shape =  (None, 224, 224, 16)\n",
            "shortcut  (post 1st conv) shape =  (None, 224, 224, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHw9-GBErMUJ"
      },
      "source": [
        "# Observations - (DECONV)\n",
        "# kernel not controlling anything in input shape\n",
        "# filters controlling the 4th dim in input shape -> filter value = 3rd dim \n",
        "# stride controlling the 2nd and 3rd dims in input shape -> stride value acts as multiplier for 1st and 2nd dim i.e 1x, 2x etc.\n",
        "\n",
        "\n",
        "# I think for each layer we will have to fiddle around with the padding and stride to change the shape\n",
        "# filter and kernel size can probably remain the same to what we were doing before since that doesnt influence anything much here and also that way we can maintain the overall size of our model (working towards that higher accuracy, lower resource usage, same size model goal)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BExsfRg7uZzx"
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyQ4bHUVYHTs"
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NzgIqZVYHWW"
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmbnZtcQYHYl"
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtK1Z_tiYHbL"
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQd6Lw2JYHdq"
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa7QdU0YYHf8"
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xvw59ghyYHho"
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50DTRCsDYHjX"
      },
      "source": [
        "# MODEL"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5camyQrYJ0T"
      },
      "source": [
        "# ----------------------------------------------Define Model---------------------------------------------------------- #\n",
        "\n",
        "# Build complete autoencoder model\n",
        "def build_autoencoder(input_shape = (224, 224, 3), describe = False):\n",
        "    '''\n",
        "    Build Autoencoder Model.\\n\n",
        "    :param input_shape: Input Shape passed to Autoencoder Model (224,224,3) (default)\\n\n",
        "    :return: Autoencoder Model\n",
        "    '''\n",
        "    def encoder(inp, input_shape=input_shape):\n",
        "        '''\n",
        "        Build Encoder Model.\\n\n",
        "        :param inp: Input to Autoencoder Model\\n\n",
        "        :param input_shape: Input Shape passed to Autoencoder Model (224,224,3) (default)\\n\n",
        "        :return: Encoder Model\n",
        "        '''\n",
        "\n",
        "        cnn_model = ResNet50(include_top = False, weights = \"imagenet\", input_shape = input_shape, pooling = \"none\")\n",
        "        cnn_model.trainable = False\n",
        "        pre_trained = tf.keras.models.Model(inputs = cnn_model.input, outputs = cnn_model.get_layer(name=\"conv3_block1_out\").output, name = \"resnet\")\n",
        "\n",
        "        # https://keras.io/guides/transfer_learning/\n",
        "        x = pre_trained(inputs = inp, training=False)\n",
        "        # print(pre_trained.summary())\n",
        "\n",
        "        layer10 = tf.keras.layers.Conv2D(filters = 512, kernel_size = 1, name = \"conv10\")(x) # for pix2vox-A(large), kernel_size is 3\n",
        "        layer10_norm = tf.keras.layers.BatchNormalization(name=\"layer10_norm\")(layer10)\n",
        "        layer10_elu = tf.keras.activations.elu(layer10_norm, name=\"layer10_elu\")\n",
        "\n",
        "        layer11 = tf.keras.layers.Conv2D(filters = 256, kernel_size = 3, name = \"conv11\")(layer10_elu) # for pix2vox-A(large), filters is 512\n",
        "        layer11_norm = tf.keras.layers.BatchNormalization(name=\"layer11_norm\")(layer11)\n",
        "        layer11_elu = tf.keras.activations.elu(layer11_norm, name=\"layer11_elu\")\n",
        "        layer11_pool = tf.keras.layers.MaxPooling2D(pool_size = (4,4), name=\"layer11_pool\")(layer11_elu) # for pix2vox-A(large), kernel size is 3\n",
        "\n",
        "        layer12 = tf.keras.layers.Conv2D(filters = 128, kernel_size = 3, name = \"conv12\")(layer11_pool) # for pix2vox-A(large), filters is 256, kernel_size is 1\n",
        "        layer12_norm = tf.keras.layers.BatchNormalization(name=\"layer12_norm\")(layer12)\n",
        "        layer12_elu = tf.keras.activations.elu(layer12_norm, name=\"layer12_elu\")\n",
        "\n",
        "        return layer12_elu\n",
        "\n",
        "    def decoder(inp):\n",
        "        '''\n",
        "        Build Decoder Model.\\n\n",
        "        :param inp: Reshaped Output of Encoder Model\\n\n",
        "        :return: Decoder Model\n",
        "        '''\n",
        "        layer1 = tf.keras.layers.Convolution3DTranspose(filters=128, kernel_size=4, strides=(2,2,2), padding=\"same\", use_bias=False, name=\"Conv3D_1\")(inp)\n",
        "        layer1_norm = tf.keras.layers.BatchNormalization(name=\"layer1_norm\")(layer1)\n",
        "        layer1_relu = tf.keras.activations.relu(layer1_norm, name=\"layer1_relu\")\n",
        "\n",
        "        layer2 = tf.keras.layers.Convolution3DTranspose(filters=64, kernel_size=4, strides=(2,2,2), padding=\"same\", use_bias=False, name=\"Conv3D_2\")(layer1_relu)\n",
        "        layer2_norm = tf.keras.layers.BatchNormalization(name=\"layer2_norm\")(layer2)\n",
        "        layer2_relu = tf.keras.activations.relu(layer2_norm, name=\"layer2_relu\")\n",
        "\n",
        "        layer3 = tf.keras.layers.Convolution3DTranspose(filters=32, kernel_size=4, strides=(2,2,2), padding=\"same\", use_bias=False, name=\"Conv3D_3\")(layer2_relu)\n",
        "        layer3_norm = tf.keras.layers.BatchNormalization(name=\"layer3_norm\")(layer3)\n",
        "        layer3_relu = tf.keras.activations.relu(layer3_norm, name=\"layer3_relu\")\n",
        "\n",
        "        layer4 = tf.keras.layers.Convolution3DTranspose(filters=8, kernel_size=4, strides=(2,2,2), padding=\"same\", use_bias=False, name=\"Conv3D_4\")(layer3_relu)\n",
        "        layer4_norm = tf.keras.layers.BatchNormalization(name=\"layer4_norm\")(layer4)\n",
        "        layer4_relu = tf.keras.activations.relu(layer4_norm, name=\"layer4_relu\")\n",
        "\n",
        "        layer5 = tf.keras.layers.Convolution3DTranspose(filters=1, kernel_size=1, use_bias=False, name=\"Conv3D_5\")(layer4_relu)\n",
        "        layer5_sigmoid = tf.keras.activations.sigmoid(layer5, name=\"layer5_sigmoid\")\n",
        "\n",
        "        # TODO: check this statement\n",
        "        layer5_sigmoid = tf.keras.layers.Reshape((32,32,32))(layer5_sigmoid)\n",
        "\n",
        "        return layer5_sigmoid\n",
        "\n",
        "    # Input\n",
        "    input = tf.keras.Input(shape = input_shape, name = \"input_layer\")\n",
        "\n",
        "    # Encoder Model\n",
        "    encoder_model = tf.keras.Model(input, encoder(input), name = \"encoder\")\n",
        "    if describe:\n",
        "        print(\"\\nEncoder Model Summary:\\n\")\n",
        "        encoder_model.summary()\n",
        "\n",
        "    # Decoder Input Reshaped from Encoder Output\n",
        "    decoder_input = tf.keras.Input(shape=(2, 2, 2, 256), name = \"decoder_input\")\n",
        "\n",
        "    # Decoder Model\n",
        "    decoder_model = tf.keras.Model(decoder_input, decoder(decoder_input), name = \"decoder\")\n",
        "    if describe:\n",
        "        print(\"\\nDecoder Model Summary:\\n\")\n",
        "        decoder_model.summary()\n",
        "\n",
        "    # Autoencoder Model\n",
        "    encoder_output = encoder_model(input)\n",
        "    # the encoder output should be reshaped to (-1,2,2,2,256) to be fed into decoder\n",
        "    decoder_input = tf.keras.layers.Reshape((2,2,2,256))(encoder_output)\n",
        "\n",
        "    autoencoder_model = tf.keras.Model(input, decoder_model(decoder_input), name ='autoencoder')\n",
        "    if describe:\n",
        "        print(\"\\nAutoencoder Model Summary:\\n\")\n",
        "        autoencoder_model.summary()\n",
        "\n",
        "    return autoencoder_model"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yc8XrROVYLII",
        "outputId": "84803fd1-4390-4998-e470-0a1ef3d51056"
      },
      "source": [
        "autoencoder_model = build_autoencoder()\n",
        "print(autoencoder_model.summary())"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "Model: \"autoencoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_layer (InputLayer)     [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "encoder (Functional)         (None, 4, 4, 128)         2354176   \n",
            "_________________________________________________________________\n",
            "reshape_5 (Reshape)          (None, 2, 2, 2, 256)      0         \n",
            "_________________________________________________________________\n",
            "decoder (Functional)         (None, 32, 32, 32)        2769832   \n",
            "=================================================================\n",
            "Total params: 5,124,008\n",
            "Trainable params: 4,508,760\n",
            "Non-trainable params: 615,248\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OugijZMCair_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}